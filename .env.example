
# ===================================
# LLM Configuration
# ===================================
LLM_TYPE=ollama
CHAT_MODEL = gemma3:1b
# CHAT_MODEL=qwen2.5:3b

# Các model khác < 4B bạn có thể dùng:
# - qwen2.5:3b (khuyến nghị - tốt cho tiếng Việt)
# - phi-2 (2.7B)
# - gemma:2b
# - stablelm2:1.6b

# ===================================
# Embedding Model Configuration
# ===================================
DENSE_MODEL = intfloat/multilingual-e5-base
# DENSE_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# Các model embedding khác bạn có thể dùng:
# - keepitreal/vietnamese-sbert (tốt cho tiếng Việt)
# - sentence-transformers/all-MiniLM-L6-v2
# - sentence-transformers/distiluse-base-multilingual-cased-v2

# ===================================
# Vector Database (Qdrant) Configuration
# ===================================
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_TIMEOUT=300

# ===================================
# Optional: Advanced Settings
# ===================================
# Chunk settings (có thể để trống, dùng default)
CHUNK_SIZE=512
CHUNK_OVERLAP=126

# Search settings
TOP_K=5
SIMILARITY_THRESHOLD=0.3

# LLM temperature (0.0 - 1.0)
TEMPERATURE=0.0