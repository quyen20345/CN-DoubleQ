import os
import pandas as pd
from pathlib import Path
from main.src.llm.chat import ask_llm
from main.src.utils.collections import COLLECTIONS
from main.src.utils.indexer import load_and_index_data
from main.src.utils._utils import chunking

class QASystem:
    def __init__(self, collection_name="technical_docs"):
        """
        Kh·ªüi t·∫°o h·ªá th·ªëng QA
        
        Args:
            collection_name: T√™n collection trong vector database
        """
        from main.src.vectordb.qdrant import VectorStore
        from main.src.embedding.model import DenseEmbedding
        
        dense_model = DenseEmbedding()
        self.vector_store = VectorStore(
            collection_name=collection_name,
            dense_model=dense_model
        )
    
    def index_extracted_data(self, extracted_data):
        """
        Index d·ªØ li·ªáu ƒë√£ tr√≠ch xu·∫•t v√†o vector database
        
        Args:
            extracted_data: dict {pdf_name: markdown_content}
        """
        print("üîÑ ƒêang index d·ªØ li·ªáu...")
        self.vector_store.recreate_collection()
        
        all_chunks = []
        for pdf_name, content in extracted_data.items():
            chunks = chunking(content)
            for chunk in chunks:
                all_chunks.append([chunk, pdf_name])
        
        if all_chunks:
            self.vector_store.insert_data(
                ["content", "source"],
                all_chunks,
                [0]
            )
        
        print(f"‚úÖ ƒê√£ index {len(all_chunks)} chunks t·ª´ {len(extracted_data)} PDF")
    
    def answer_question(self, question, options):
        """
        Tr·∫£ l·ªùi c√¢u h·ªèi tr·∫Øc nghi·ªám
        
        Args:
            question: C√¢u h·ªèi
            options: Dict {'A': '...', 'B': '...', 'C': '...', 'D': '...'}
        
        Returns:
            tuple: (s·ªë_c√¢u_ƒë√∫ng, list_ƒë√°p_√°n_ƒë√∫ng)
        """
        # T√¨m context li√™n quan
        search_results = self.vector_store.search(question, top_k=5, threshold=0.3)
        
        if not search_results:
            # N·∫øu kh√¥ng t√¨m th·∫•y context, d√πng LLM tr·ª±c ti·∫øp
            context = "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan."
        else:
            context = "\n\n".join([
                f"[Ngu·ªìn: {point.payload.get('source', 'Unknown')}]\n{point.payload.get('content', '')}"
                for point in search_results
            ])
        
        # T·∫°o prompt cho LLM
        prompt = self._create_qa_prompt(question, options, context)
        
        # G·ªçi LLM
        response = ask_llm(prompt)
        
        # Parse k·∫øt qu·∫£
        correct_count, correct_answers = self._parse_llm_response(response)
        
        return correct_count, correct_answers
    
    def _create_qa_prompt(self, question, options, context):
        """T·∫°o prompt cho LLM"""
        options_text = "\n".join([f"{key}. {value}" for key, value in options.items()])
        
        prompt = f"""D·ª±a tr√™n th√¥ng tin sau ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi tr·∫Øc nghi·ªám.

TH√îNG TIN T√ÄI LI·ªÜU:
{context}

C√ÇU H·ªéI:
{question}

C√ÅC L·ª∞A CH·ªåN:
{options_text}

Y√äU C·∫¶U:
- C√¢u h·ªèi c√≥ th·ªÉ c√≥ NHI·ªÄU ƒë√°p √°n ƒë√∫ng (t·ª´ 1 ƒë·∫øn 4 ƒë√°p √°n)
- Ph√¢n t√≠ch k·ªπ t·ª´ng l·ª±a ch·ªçn d·ª±a tr√™n th√¥ng tin t√†i li·ªáu
- Tr·∫£ l·ªùi theo ƒë·ªãnh d·∫°ng:
  S·ªë c√¢u ƒë√∫ng: <s·ªë>
  ƒê√°p √°n ƒë√∫ng: <A,B,C,D>

V√ç D·ª§:
S·ªë c√¢u ƒë√∫ng: 2
ƒê√°p √°n ƒë√∫ng: A,C

PH√ÇN T√çCH V√Ä TR·∫¢ L·ªúI:"""
        
        return prompt
    
    def _parse_llm_response(self, response):
        """
        Parse response t·ª´ LLM
        
        Returns:
            tuple: (correct_count, correct_answers_list)
        """
        import re
        
        # T√¨m s·ªë c√¢u ƒë√∫ng
        count_match = re.search(r'S·ªë c√¢u ƒë√∫ng:\s*(\d+)', response)
        correct_count = int(count_match.group(1)) if count_match else 1
        
        # T√¨m ƒë√°p √°n ƒë√∫ng
        answers_match = re.search(r'ƒê√°p √°n ƒë√∫ng:\s*([A-D,\s]+)', response)
        if answers_match:
            answers_str = answers_match.group(1).strip()
            correct_answers = [ans.strip() for ans in answers_str.split(',') if ans.strip()]
        else:
            # Fallback: t√¨m c√°c ch·ªØ c√°i A-D trong response
            correct_answers = list(set(re.findall(r'\b([A-D])\b', response)))
            correct_answers.sort()
        
        # ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng ƒë√°p √°n kh·ªõp
        if len(correct_answers) != correct_count:
            correct_count = len(correct_answers)
        
        return correct_count, correct_answers
    
    def process_questions_csv(self, csv_path):
        """
        X·ª≠ l√Ω t·∫•t c·∫£ c√¢u h·ªèi t·ª´ CSV
        
        Args:
            csv_path: ƒê∆∞·ªùng d·∫´n file question.csv
        
        Returns:
            list: [(correct_count, correct_answers), ...]
        """
        df = pd.read_csv(csv_path)
        results = []
        
        print(f"\nü§î B·∫Øt ƒë·∫ßu tr·∫£ l·ªùi {len(df)} c√¢u h·ªèi...")
        
        for idx, row in df.iterrows():
            question = row.iloc[0]  # C·ªôt ƒë·∫ßu ti√™n l√† c√¢u h·ªèi
            options = {
                'A': row.iloc[1],
                'B': row.iloc[2],
                'C': row.iloc[3],
                'D': row.iloc[4]
            }
            
            print(f"\nC√¢u {idx + 1}/{len(df)}: {question[:50]}...")
            
            correct_count, correct_answers = self.answer_question(question, options)
            results.append((correct_count, correct_answers))
            
            print(f"  ‚ûú S·ªë c√¢u ƒë√∫ng: {correct_count}, ƒê√°p √°n: {','.join(correct_answers)}")
        
        return results


def run_qa_pipeline(pdf_dir, question_csv, output_dir):
    """
    Ch·∫°y to√†n b·ªô pipeline: Extract + Index + QA
    
    Args:
        pdf_dir: Th∆∞ m·ª•c ch·ª©a PDF
        question_csv: File CSV c√¢u h·ªèi
        output_dir: Th∆∞ m·ª•c output
    """
    from extract_pdf import extract_all_pdfs
    
    # B∆∞·ªõc 1: Tr√≠ch xu·∫•t PDF
    print("=" * 60)
    print("B∆Ø·ªöC 1: TR√çCH XU·∫§T PDF")
    print("=" * 60)
    extracted_data = extract_all_pdfs(pdf_dir, output_dir)
    
    # B∆∞·ªõc 2: Index d·ªØ li·ªáu
    print("\n" + "=" * 60)
    print("B∆Ø·ªöC 2: INDEX D·ªÆ LI·ªÜU")
    print("=" * 60)
    qa_system = QASystem(collection_name="technical_docs_qa")
    qa_system.index_extracted_data(extracted_data)
    
    # B∆∞·ªõc 3: Tr·∫£ l·ªùi c√¢u h·ªèi
    print("\n" + "=" * 60)
    print("B∆Ø·ªöC 3: TR·∫¢ L·ªúI C√ÇU H·ªéI")
    print("=" * 60)
    results = qa_system.process_questions_csv(question_csv)
    
    return extracted_data, results


if __name__ == "__main__":
    # Test
    pdf_dir = "main/data/processed/public_test/pdfs"
    question_csv = "main/data/processed/public_test/question.csv"
    output_dir = "main/output/public_test_output"
    
    extracted_data, results = run_qa_pipeline(pdf_dir, question_csv, output_dir)
    
    print("\n" + "=" * 60)
    print("‚úÖ HO√ÄN TH√ÄNH!")
    print("=" * 60)