# -*- coding: utf-8 -*-
"""
Tá»‡p mÃ£ nguá»“n tá»•ng há»£p cho Nhiá»‡m vá»¥ 2: Khai phÃ¡ tri thá»©c tá»« vÄƒn báº£n ká»¹ thuáº­t.

Tá»‡p nÃ y chá»©a toÃ n bá»™ pipeline, bao gá»“m:
1. TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« file PDF sang Ä‘á»‹nh dáº¡ng Markdown.
2. Láº­p chá»‰ má»¥c (index) ná»™i dung Ä‘Ã£ trÃ­ch xuáº¥t vÃ o Vector Database (Qdrant).
3. Há»‡ thá»‘ng Há»i-ÄÃ¡p (QA) Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i tráº¯c nghiá»‡m.
4. Táº¡o tá»‡p output cuá»‘i cÃ¹ng (`answer.md` vÃ  file zip) theo Ä‘Ãºng Ä‘á»‹nh dáº¡ng yÃªu cáº§u.

Äá»ƒ cháº¡y chÆ°Æ¡ng trÃ¬nh, sá»­ dá»¥ng command line vá»›i cÃ¡c tÃ¹y chá»n phÃ¹ há»£p.
VÃ­ dá»¥:
- Cháº¡y toÃ n bá»™ pipeline cho public test:
  python3 main.py --mode public --task full

- Chá»‰ cháº¡y pháº§n trÃ­ch xuáº¥t vÃ  index cho public test:
  python3 main.py --mode public --task extract

- Chá»‰ cháº¡y pháº§n tráº£ lá»i cÃ¢u há»i cho public test (sau khi Ä‘Ã£ extract):
  python3 main.py --mode public --task qa
"""

# ==============================================================================
# 0. IMPORTS & SETUP
# ==============================================================================
import os
import re
import sys
import shutil
import argparse
import uuid
import zipfile
from pathlib import Path
import pandas as pd

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
# pip install "python-dotenv==1.0.1" "pandas==2.2.2" "sentence-transformers==3.0.1" "qdrant-client==1.9.2" "langchain==0.2.6" "langchain-ollama==0.1.0" "jinja2==3.1.4" "docling==0.0.15" "tiktoken==0.7.0"

# Táº£i .env file náº¿u cÃ³
try:
    from dotenv import load_dotenv
    if Path('.env').exists():
        print("Äang táº£i biáº¿n mÃ´i trÆ°á»ng tá»« file .env...")
        load_dotenv()
except ImportError:
    print("Cáº£nh bÃ¡o: ThÆ° viá»‡n python-dotenv chÆ°a Ä‘Æ°á»£c cÃ i. Sá»­ dá»¥ng biáº¿n mÃ´i trÆ°á»ng há»‡ thá»‘ng.")

# ==============================================================================
# 1. EMBEDDING MODEL (tá»« main/src/embedding/model.py)
# ==============================================================================
try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("Lá»—i: sentence-transformers chÆ°a Ä‘Æ°á»£c cÃ i. Vui lÃ²ng cháº¡y: pip install sentence-transformers")
    sys.exit(1)

class DenseEmbedding:
    """Quáº£n lÃ½ mÃ´ hÃ¬nh embedding Ä‘á»ƒ chuyá»ƒn vÄƒn báº£n thÃ nh vector."""
    def __init__(self, model_name=os.getenv("DENSE_MODEL", "vinai/phobert-base-v2")):
        print(f"Äang khá»Ÿi táº¡o mÃ´ hÃ¬nh embedding: {model_name}")
        # Táº¡o thÆ° má»¥c cache trong project Ä‘á»ƒ lÆ°u model
        cache_dir = Path(__file__).parent / "embedding_models"
        cache_dir.mkdir(exist_ok=True)
        self.model = SentenceTransformer(model_name, cache_folder=str(cache_dir))
        print("âœ… Khá»Ÿi táº¡o mÃ´ hÃ¬nh embedding thÃ nh cÃ´ng.")

    def encode(self, texts):
        if isinstance(texts, str):
            return self.model.encode(texts)
        elif isinstance(texts, list):
            return [e.tolist() for e in self.model.encode(texts)]
        else:
            raise ValueError("Äáº§u vÃ o pháº£i lÃ  chuá»—i hoáº·c danh sÃ¡ch cÃ¡c chuá»—i.")
        
    def get_dimension(self):
        # Tráº£ vá» sá»‘ chiá»u cá»§a vector embedding
        return self.model.get_sentence_embedding_dimension()

# ==============================================================================
# 2. VECTOR DATABASE (tá»« main/src/vectordb/qdrant.py)
# ==============================================================================
try:
    from qdrant_client import QdrantClient, models
except ImportError:
    print("Lá»—i: qdrant-client chÆ°a Ä‘Æ°á»£c cÃ i. Vui lÃ²ng cháº¡y: pip install qdrant-client")
    sys.exit(1)

class VectorStore:
    """Quáº£n lÃ½ viá»‡c lÆ°u trá»¯ vÃ  truy váº¥n vector táº¡i Qdrant."""
    def __init__(self, collection_name, dense_model):
        self.collection_name = collection_name
        self.dense_embedding_model = dense_model
        
        try:
            host = os.getenv("QDRANT_HOST", "localhost")
            port = int(os.getenv("QDRANT_PORT", 6333))
            print(f"Äang káº¿t ná»‘i tá»›i Qdrant táº¡i {host}:{port}...")
            self.client = QdrantClient(host=host, port=port, timeout=int(os.getenv("QDRANT_TIMEOUT", 60)))
            self.client.get_collections() # Kiá»ƒm tra káº¿t ná»‘i
            print("âœ… Káº¿t ná»‘i Qdrant thÃ nh cÃ´ng.")
        except Exception as e:
            print(f"âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i tá»›i Qdrant: {e}")
            print("HÃ£y cháº¯c cháº¯n ráº±ng báº¡n Ä‘Ã£ khá»Ÿi cháº¡y Qdrant (vÃ­ dá»¥: báº±ng docker-compose).")
            sys.exit(1)

        if not self.client.collection_exists(self.collection_name):
            self._create_collection()

    def _create_collection(self):
        print(f"Äang táº¡o collection má»›i: {self.collection_name}")
        self.client.create_collection(
            collection_name=self.collection_name,
            vectors_config=models.VectorParams(
                size=self.dense_embedding_model.get_dimension(),
                distance=models.Distance.COSINE,
            ),
        )

    def recreate_collection(self):
        print(f"Äang xÃ³a vÃ  táº¡o láº¡i collection: {self.collection_name}")
        if self.client.collection_exists(self.collection_name):
            self.client.delete_collection(self.collection_name)
        self._create_collection()
        print("âœ… Táº¡o láº¡i collection thÃ nh cÃ´ng.")

    def insert_data(self, payload_keys, payload_values):
        if not payload_values:
            return
        
        contents = [item[0] for item in payload_values]
        dense_embeddings = self.dense_embedding_model.encode(contents)

        points = [
            models.PointStruct(
                id=str(uuid.uuid4()),
                vector=dense_embeddings[i],
                payload=dict(zip(payload_keys, payload_values[i]))
            )
            for i in range(len(dense_embeddings))
        ]
        
        # Upsert theo batch
        BATCH_SIZE = 100
        for i in range(0, len(points), BATCH_SIZE):
            batch = points[i:i + BATCH_SIZE]
            self.client.upsert(collection_name=self.collection_name, points=batch, wait=True)
            print(f"  > ÄÃ£ upsert batch {i // BATCH_SIZE + 1}/{len(points) // BATCH_SIZE + 1}")

    def search(self, query, top_k=5, threshold=0.3):
        query_vector = self.dense_embedding_model.encode(query)
        hits = self.client.search(
            collection_name=self.collection_name,
            query_vector=query_vector,
            limit=top_k,
            score_threshold=threshold
        )
        return hits

# ==============================================================================
# 3. LLM INTEGRATION (tá»« main/src/llm/*.py)
# ==============================================================================
try:
    from langchain_ollama import OllamaLLM
    from jinja2 import Template
except ImportError:
    print("Lá»—i: langchain-ollama hoáº·c jinja2 chÆ°a Ä‘Æ°á»£c cÃ i. Vui lÃ²ng cÃ i Ä‘áº·t.")
    sys.exit(1)

class LLMManager:
    """Quáº£n lÃ½ viá»‡c tÆ°Æ¡ng tÃ¡c vá»›i Large Language Model."""
    def __init__(self):
        llm_type = os.getenv("LLM_TYPE", "ollama")
        if llm_type != "ollama":
            raise ValueError("Hiá»‡n chá»‰ há»— trá»£ LLM_TYPE=ollama")
        
        model_name = os.getenv("CHAT_MODEL", "llama3:instruct")
        print(f"Äang khá»Ÿi táº¡o LLM: {model_name}")
        self.llm = OllamaLLM(model=model_name, temperature=0.0)
        print("âœ… Khá»Ÿi táº¡o LLM thÃ nh cÃ´ng.")

    def ask(self, prompt):
        try:
            response = self.llm.invoke(prompt)
            return response.strip()
        except Exception as e:
            print(f"âŒ Lá»—i khi gá»i LLM: {e}")
            print("HÃ£y cháº¯c cháº¯n ráº±ng Ollama Ä‘ang cháº¡y vÃ  model Ä‘Ã£ Ä‘Æ°á»£c pull (vd: ollama run llama3:instruct).")
            # Fallback response
            return "Sá»‘ cÃ¢u Ä‘Ãºng: 1\nÄÃ¡p Ã¡n Ä‘Ãºng: A"

# ==============================================================================
# 4. PDF EXTRACTION (tá»« extract_pdf.py)
# ==============================================================================
try:
    from docling.document_converter import DocumentConverter, PdfFormatOption
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode
except ImportError:
    print("Lá»—i: docling chÆ°a Ä‘Æ°á»£c cÃ i. Vui lÃ²ng cháº¡y: pip install docling")
    sys.exit(1)

class PDFExtractor:
    """TrÃ­ch xuáº¥t ná»™i dung tá»« tá»‡p PDF sang Markdown."""
    def __init__(self):
        pipeline_options = PdfPipelineOptions()
        pipeline_options.do_table_structure = True
        pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE
        
        self.converter = DocumentConverter(
            format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}
        )
    
    def extract_pdf(self, pdf_path, output_dir):
        output_dir_path = Path(output_dir)
        output_dir_path.mkdir(parents=True, exist_ok=True)
        images_dir = output_dir_path / "images"
        images_dir.mkdir(exist_ok=True)
        
        print(f"Äang xá»­ lÃ½ PDF: {pdf_path}")
        result = self.converter.convert(str(pdf_path))
        doc = result.document
        
        # LÆ°u hÃ¬nh áº£nh vÃ  cÃ´ng thá»©c (náº¿u cÃ³)
        # Theo yÃªu cáº§u, chÃºng ta chá»‰ cáº§n placeholder
        if hasattr(doc, 'pictures'):
            for i, picture in enumerate(doc.pictures):
                try:
                    if hasattr(picture, 'image') and picture.image:
                        img_path = images_dir / f"image_{i+1}.png"
                        picture.image.pil_image.save(img_path)
                except Exception as e:
                    print(f"  > Cáº£nh bÃ¡o: KhÃ´ng thá»ƒ lÆ°u áº£nh {i+1}. Lá»—i: {e}")

        # Export ra markdown vÃ  thay tháº¿ placeholders
        md_content = doc.export_to_markdown()
        md_content = re.sub(r'!\[.*?\]\(data:image/.*?\)', r'|<image_placeholder>|', md_content)
        md_content = re.sub(r'<img src="data:image/.*?">', r'|<image_placeholder>|', md_content)
        
        # ÄÃ¡nh sá»‘ láº¡i placeholders
        image_counter = 1
        formula_counter = 1
        
        def replace_image(match):
            nonlocal image_counter
            res = f"|<image_{image_counter}>|"
            image_counter += 1
            return res

        def replace_formula(match):
            nonlocal formula_counter
            res = f"|<formula_{formula_counter}>|"
            formula_counter += 1
            return res
            
        md_content = re.sub(r'\|<image_placeholder>\|', replace_image, md_content)
        md_content = re.sub(r'\$\$[\s\S]*?\$\$', replace_formula, md_content) # Block formula
        md_content = re.sub(r'\$[^\$]*?\$', replace_formula, md_content) # Inline formula

        main_md_path = output_dir_path / "main.md"
        with open(main_md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"âœ… ÄÃ£ trÃ­ch xuáº¥t xong: {main_md_path}")
        return md_content

    def extract_all_pdfs(self, input_dir, output_base_dir):
        extracted_data = {}
        # Sá»­a lá»—i: TÃ¬m kiáº¿m file .pdf trong cáº£ cÃ¡c thÆ° má»¥c con
        pdf_files = list(Path(input_dir).rglob("*.pdf"))
        
        if not pdf_files:
            print(f"Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y file PDF nÃ o trong '{input_dir}'")
            return {}

        for pdf_path in pdf_files:
            pdf_name = pdf_path.stem
            output_dir = Path(output_base_dir) / pdf_name
            markdown_content = self.extract_pdf(pdf_path, output_dir)
            extracted_data[pdf_name] = markdown_content
        return extracted_data

# ==============================================================================
# 5. QA SYSTEM (tá»« qa_system.py vÃ  _utils.py)
# ==============================================================================
try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
except ImportError:
    print("Lá»—i: langchain chÆ°a Ä‘Æ°á»£c cÃ i. Vui lÃ²ng cháº¡y: pip install langchain tiktoken")
    sys.exit(1)

def chunking(text):
    """PhÃ¢n nhá» vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n cÃ³ kÃ­ch thÆ°á»›c phÃ¹ há»£p."""
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=512, chunk_overlap=100
    )
    chunks = text_splitter.split_text(text)
    return [chunk for chunk in chunks if len(chunk.strip()) >= 50]

class QASystem:
    """Há»‡ thá»‘ng tráº£ lá»i cÃ¢u há»i tráº¯c nghiá»‡m."""
    def __init__(self, vector_store, llm_manager):
        self.vector_store = vector_store
        self.llm_manager = llm_manager
    
    def index_data(self, extracted_data):
        print("ğŸ”„ Äang index dá»¯ liá»‡u vÃ o vector database...")
        self.vector_store.recreate_collection()
        
        all_chunks = []
        for pdf_name, content in extracted_data.items():
            chunks = chunking(content)
            for chunk in chunks:
                all_chunks.append([chunk, pdf_name])
        
        if all_chunks:
            self.vector_store.insert_data(["content", "source"], all_chunks)
        
        print(f"âœ… ÄÃ£ index {len(all_chunks)} chunks tá»« {len(extracted_data)} PDF.")
    
    def answer_question(self, question, options):
        # TÃ¬m kiáº¿m context liÃªn quan
        search_results = self.vector_store.search(question, top_k=5, threshold=0.3)
        
        context = "\n\n---\n\n".join([
            f"Nguá»“n: {point.payload.get('source', 'KhÃ´ng rÃµ')}\n\n{point.payload.get('content', '')}"
            for point in search_results
        ]) if search_results else "KhÃ´ng cÃ³ thÃ´ng tin nÃ o Ä‘Æ°á»£c tÃ¬m tháº¥y trong tÃ i liá»‡u."
        
        prompt = self._create_qa_prompt(question, options, context)
        response = self.llm_manager.ask(prompt)
        return self._parse_llm_response(response)
    
    def _create_qa_prompt(self, question, options, context):
        options_text = "\n".join([f"{key}. {value}" for key, value in options.items()])
        
        return f"""Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch tÃ i liá»‡u ká»¹ thuáº­t. Dá»±a vÃ o "THÃ”NG TIN TÃ€I LIá»†U" dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i tráº¯c nghiá»‡m má»™t cÃ¡ch chÃ­nh xÃ¡c.

### THÃ”NG TIN TÃ€I LIá»†U:
{context}

---

### CÃ‚U Há»I:
{question}

### CÃC Lá»°A CHá»ŒN:
{options_text}

### YÃŠU Cáº¦U:
1. Äá»c ká»¹ cÃ¢u há»i vÃ  táº¥t cáº£ cÃ¡c lá»±a chá»n.
2. Äá»‘i chiáº¿u Tá»ªNG lá»±a chá»n vá»›i "THÃ”NG TIN TÃ€I LIá»†U".
3. CÃ¢u há»i cÃ³ thá»ƒ cÃ³ Má»˜T hoáº·c NHIá»€U Ä‘Ã¡p Ã¡n Ä‘Ãºng.
4. Chá»‰ chá»n nhá»¯ng Ä‘Ã¡p Ã¡n Ä‘Æ°á»£c xÃ¡c nháº­n HOÃ€N TOÃ€N bá»Ÿi tÃ i liá»‡u.
5. Tráº£ lá»i theo Ä‘á»‹nh dáº¡ng JSON nghiÃªm ngáº·t sau Ä‘Ã¢y, khÃ´ng thÃªm báº¥t ká»³ giáº£i thÃ­ch nÃ o khÃ¡c.

{{
  "correct_count": <sá»‘ lÆ°á»£ng Ä‘Ã¡p Ã¡n Ä‘Ãºng>,
  "correct_answers": ["<A>", "<B>", ...]
}}

VÃ­ dá»¥:
{{
  "correct_count": 2,
  "correct_answers": ["A", "C"]
}}

### TRáº¢ Lá»œI (CHá»ˆ JSON):
"""

    def _parse_llm_response(self, response):
        try:
            import json
            # TÃ¬m vÃ  trÃ­ch xuáº¥t chuá»—i JSON tá»« response
            match = re.search(r'\{[\s\S]*\}', response)
            if match:
                json_str = match.group(0)
                data = json.loads(json_str)
                count = data.get("correct_count", 0)
                answers = data.get("correct_answers", [])
                
                # XÃ¡c thá»±c láº¡i dá»¯ liá»‡u
                answers = [ans for ans in answers if ans in ['A', 'B', 'C', 'D']]
                if count != len(answers):
                    print(f"  > Cáº£nh bÃ¡o: LLM tráº£ vá» sá»‘ lÆ°á»£ng khÃ´ng khá»›p. count={count}, answers={answers}. Tá»± Ä‘á»™ng sá»­a láº¡i.")
                    count = len(answers)
                
                return count, answers
            else:
                raise ValueError("KhÃ´ng tÃ¬m tháº¥y JSON trong response.")
        except (json.JSONDecodeError, ValueError) as e:
            print(f"  > Cáº£nh bÃ¡o: KhÃ´ng thá»ƒ parse JSON tá»« LLM. Lá»—i: {e}. Response: '{response[:100]}...'")
            # Fallback: DÃ¹ng regex Ä‘á»ƒ tÃ¬m cÃ¢u tráº£ lá»i
            answers = sorted(list(set(re.findall(r'\b([A-D])\b', response.upper()))))
            return len(answers), answers
    
    def process_questions_csv(self, csv_path):
        try:
            df = pd.read_csv(csv_path)
        except FileNotFoundError:
            print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file question.csv táº¡i '{csv_path}'")
            return None
            
        results = []
        print(f"\nğŸ¤” Báº¯t Ä‘áº§u tráº£ lá»i {len(df)} cÃ¢u há»i...")
        
        for idx, row in df.iterrows():
            question = row.iloc[0]
            options = { 'A': row.iloc[1], 'B': row.iloc[2], 'C': row.iloc[3], 'D': row.iloc[4] }
            
            print(f"\nCÃ¢u {idx + 1}/{len(df)}: {question[:80]}...")
            
            count, answers = self.answer_question(question, options)
            results.append((count, answers))
            
            print(f"  âœ Káº¿t quáº£: {count} cÃ¢u Ä‘Ãºng - ÄÃ¡p Ã¡n: {', '.join(answers) if answers else 'KhÃ´ng cÃ³'}")
        
        return results

# ==============================================================================
# 6. ANSWER GENERATOR (tá»« answer_generator.py)
# ==============================================================================
class AnswerGenerator:
    """Táº¡o file output cuá»‘i cÃ¹ng theo Ä‘á»‹nh dáº¡ng cá»§a cuá»™c thi."""
    def __init__(self, output_dir):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_answer_md(self, extracted_data, qa_results):
        """
        Táº¡o file answer.md vá»›i pháº§n QA theo Ä‘á»‹nh dáº¡ng CSV.
        """
        content = []
        
        # Pháº§n 1: TASK EXTRACT
        content.append("### TASK EXTRACT")
        for pdf_name, md_content in sorted(extracted_data.items()):
            content.append(f"\n# {pdf_name}\n")
            content.append(md_content)
        
        # Pháº§n 2: TASK QA (Äá»‹nh dáº¡ng CSV)
        content.append("\n### TASK QA")
        if qa_results:
            # ThÃªm header cho CSV
            content.append("num_correct,answers")
            for count, answers in qa_results:
                # Sáº¯p xáº¿p cÃ¡c Ä‘Ã¡p Ã¡n Ä‘á»ƒ Ä‘áº£m báº£o thá»© tá»± nháº¥t quÃ¡n
                sorted_answers = sorted(answers)
                # GhÃ©p cÃ¡c Ä‘Ã¡p Ã¡n thÃ nh má»™t chuá»—i, vÃ­ dá»¥: "A,B"
                formatted_answers = ",".join(sorted_answers)
                
                # Náº¿u cÃ³ nhiá»u hÆ¡n má»™t Ä‘Ã¡p Ã¡n, Ä‘áº·t chuá»—i vÃ o trong dáº¥u ngoáº·c kÃ©p
                if len(sorted_answers) > 1:
                    formatted_answers = f'"{formatted_answers}"'
                
                # ThÃªm dÃ²ng CSV vÃ o ná»™i dung
                content.append(f"{count},{formatted_answers}")
        
        answer_md_path = self.output_dir / "answer.md"
        with open(answer_md_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content))
        
        print(f"âœ… ÄÃ£ táº¡o file answer.md táº¡i: {answer_md_path}")


    def create_zip(self, zip_name):
        zip_path = self.output_dir.parent / zip_name
        print(f"ğŸ“¦ Äang táº¡o file zip: {zip_path}...")
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, _, files in os.walk(self.output_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    archive_name = os.path.relpath(file_path, self.output_dir)
                    zipf.write(file_path, archive_name)

        print(f"âœ… ÄÃ£ táº¡o file zip thÃ nh cÃ´ng: {zip_path}")

# ==============================================================================
# 7. MAIN PIPELINE LOGIC
# ==============================================================================
def setup_paths(mode):
    """Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n input vÃ  output dá»±a trÃªn mode."""
    # Sá»­a lá»—i: Trá» Ä‘áº¿n Ä‘Ãºng thÆ° má»¥c data theo prepare_data.sh
    base_input_dir = Path(f"main/data/{mode}_test_input")
    output_dir = Path(f"output/{mode}_test_output")
    
    # Táº¡o cÃ¡c thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
    base_input_dir.mkdir(parents=True, exist_ok=True)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Sá»­a lá»—i: TÃ¬m file question.csv trong cáº£ cÃ¡c thÆ° má»¥c con
    question_csv_paths = list(base_input_dir.rglob("question.csv"))
    if not question_csv_paths:
        # Náº¿u khÃ´ng tÃ¬m tháº¥y, giá»¯ Ä‘Æ°á»ng dáº«n cÅ© Ä‘á»ƒ bÃ¡o lá»—i rÃµ rÃ ng
        question_csv_path = base_input_dir / "question.csv"
    else:
        # Láº¥y Ä‘Æ°á»ng dáº«n Ä‘áº§u tiÃªn tÃ¬m Ä‘Æ°á»£c
        question_csv_path = question_csv_paths[0]
        print(f"ÄÃ£ tÃ¬m tháº¥y file question.csv táº¡i: {question_csv_path}")

    paths = {
        "pdf_dir": base_input_dir,
        "question_csv": question_csv_path,
        "output_dir": output_dir,
        "zip_name": f"{mode}_test_output.zip"
    }
    
    print("\n--- Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n ---")
    for key, value in paths.items():
        print(f"{key:<15}: {value}")
    print("---------------------------\n")
    
    return paths

def run_task_extract(paths):
    """Cháº¡y tÃ¡c vá»¥ trÃ­ch xuáº¥t vÃ  index."""
    print("\n" + "="*25 + " Báº®T Äáº¦U TÃC Vá»¤ EXTRACT " + "="*25)
    
    # 1. Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n
    extractor = PDFExtractor()
    embedding_model = DenseEmbedding()
    vector_db = VectorStore(f"collection_{Path(paths['pdf_dir']).name}", embedding_model)
    qa_system = QASystem(vector_db, None) # KhÃ´ng cáº§n LLM cho task nÃ y

    # 2. TrÃ­ch xuáº¥t PDF
    extracted_data = extractor.extract_all_pdfs(paths["pdf_dir"], paths["output_dir"])
    if not extracted_data:
        print("âŒ Káº¿t thÃºc tÃ¡c vá»¥ extract vÃ¬ khÃ´ng cÃ³ dá»¯ liá»‡u PDF.")
        return False

    # 3. Index dá»¯ liá»‡u
    qa_system.index_data(extracted_data)
    
    print("\n" + "="*25 + " HOÃ€N THÃ€NH TÃC Vá»¤ EXTRACT " + "="*24)
    return True

def run_task_qa(paths):
    """Cháº¡y tÃ¡c vá»¥ tráº£ lá»i cÃ¢u há»i vÃ  táº¡o output."""
    print("\n" + "="*28 + " Báº®T Äáº¦U TÃC Vá»¤ QA " + "="*28)
    
    # 1. Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n
    embedding_model = DenseEmbedding()
    vector_db = VectorStore(f"collection_{Path(paths['pdf_dir']).name}", embedding_model)
    llm = LLMManager()
    qa_system = QASystem(vector_db, llm)

    # 2. Äá»c láº¡i dá»¯ liá»‡u Ä‘Ã£ trÃ­ch xuáº¥t tá»« file main.md
    extracted_data = {}
    output_dir_path = Path(paths["output_dir"])
    for subdir in output_dir_path.iterdir():
        if subdir.is_dir():
            main_md = subdir / "main.md"
            if main_md.exists():
                pdf_name = subdir.name
                extracted_data[pdf_name] = main_md.read_text(encoding='utf-8')

    if not extracted_data:
        print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u Ä‘Ã£ trÃ­ch xuáº¥t trong thÆ° má»¥c output.")
        print("Vui lÃ²ng cháº¡y tÃ¡c vá»¥ 'extract' trÆ°á»›c: python3 main.py --task extract")
        return

    # 3. Tráº£ lá»i cÃ¢u há»i
    qa_results = qa_system.process_questions_csv(paths["question_csv"])
    if qa_results is None:
        print("âŒ Káº¿t thÃºc tÃ¡c vá»¥ QA vÃ¬ khÃ´ng thá»ƒ xá»­ lÃ½ file cÃ¢u há»i.")
        return

    # 4. Táº¡o file output
    generator = AnswerGenerator(paths["output_dir"])
    generator.generate_answer_md(extracted_data, qa_results)
    
    # 5. Copy file main.py vÃ  táº¡o zip
    print(f"Äang copy file mÃ£ nguá»“n '{Path(__file__).name}' vÃ o thÆ° má»¥c output...")
    shutil.copy(Path(__file__), output_dir_path / "main.py")
    generator.create_zip(paths["zip_name"])
    
    print("\n" + "="*27 + " HOÃ€N THÃ€NH TÃC Vá»¤ QA " + "="*28)


def main():
    """HÃ m main Ä‘á»ƒ cháº¡y pipeline tá»« command line."""
    parser = argparse.ArgumentParser(description="Pipeline cho Nhiá»‡m vá»¥ 2 - Zalo AI Challenge")
    
    parser.add_argument(
        "--mode", type=str, choices=["public", "private", "training"], default="public",
        help="Cháº¿ Ä‘á»™ cháº¡y: public, private hoáº·c training test."
    )
    parser.add_argument(
        "--task", type=str, choices=["extract", "qa", "full"], default="full",
        help="TÃ¡c vá»¥ cáº§n thá»±c hiá»‡n: extract (trÃ­ch xuáº¥t & index), qa (tráº£ lá»i cÃ¢u há»i), full (toÃ n bá»™ pipeline)."
    )
    
    args = parser.parse_args()
    
    print("\n" + "*"*80)
    print(f" Báº®T Äáº¦U PIPELINE - CHáº¾ Äá»˜: {args.mode.upper()} - TÃC Vá»¤: {args.task.upper()} ".center(80, '*'))
    print("*"*80)

    # Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n
    paths = setup_paths(args.mode)

    if args.task == "extract":
        run_task_extract(paths)
    elif args.task == "qa":
        run_task_qa(paths)
    elif args.task == "full":
        if run_task_extract(paths):
            run_task_qa(paths)
    
    print("\n" + "*"*80)
    print(f" PIPELINE Káº¾T THÃšC ".center(80, '*'))
    print("*"*80 + "\n")


if __name__ == "__main__":
    # Sá»­a lá»—i: XÃ³a dÃ²ng os.chdir Ä‘á»ƒ Ä‘áº£m báº£o script cháº¡y Ä‘Ãºng tá»« thÆ° má»¥c gá»‘c cá»§a project.
    main()
