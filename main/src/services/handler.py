# -*- coding: utf-8 -*-
import re
import json
import pandas as pd
from pathlib import Path
from typing import List, Tuple

from main.src.llm.llm_integrations import get_llm
from main.src.vectordb.qdrant import VectorStore


class QAHandler:
    """Xá»­ lÃ½ toÃ n bá»™ logic cho viá»‡c tráº£ lá»i cÃ¢u há»i vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n."""
    
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.llm = get_llm()

    def _create_qa_prompt(self, question: str, options: dict, context: str) -> str:
        """Táº¡o prompt tá»‘i Æ°u vá»›i Chain-of-Thought vÃ  few-shot examples."""
        options_text = "\n".join([f"{key}. {value}" for key, value in options.items()])
        
        return f"""Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch tÃ i liá»‡u ká»¹ thuáº­t IoT/Smart Home vá»›i kháº£ nÄƒng reasoning cao.

### NGUYÃŠN Táº®C QUAN TRá»ŒNG:
1. CHá»ˆ chá»n Ä‘Ã¡p Ã¡n Ä‘Æ°á»£c KHáº²NG Äá»ŠNH RÃ• RÃ€NG trong tÃ i liá»‡u
2. Náº¿u tÃ i liá»‡u KHÃ”NG Äá»€ Cáº¬P, Ä‘Ã¡p Ã¡n Ä‘Ã³ lÃ  SAI
3. CÃ¢u há»i cÃ³ thá»ƒ cÃ³ 1, 2, 3, hoáº·c 4 Ä‘Ã¡p Ã¡n Ä‘Ãºng
4. Äá»c Ká»¸ tá»«ng lá»±a chá»n, khÃ´ng bá» sÃ³t chi tiáº¿t
5. ChÃº Ã½ tá»« phá»§ Ä‘á»‹nh: "KHÃ”NG", "NGOáº I TRá»ª", "TRá»ª"

### TÃ€I LIá»†U THAM KHáº¢O:
{context}

---

### CÃ‚U Há»I:
{question}

### CÃC Lá»°A CHá»ŒN:
{options_text}

### PHÆ¯Æ NG PHÃP TRáº¢ Lá»œI (THá»°C HIá»†N TUáº¦N Tá»°):

**BÆ°á»›c 1: PhÃ¢n tÃ­ch cÃ¢u há»i**
- XÃ¡c Ä‘á»‹nh thÃ´ng tin cáº§n tÃ¬m
- ChÃº Ã½ tá»« khÃ³a quan trá»ng
- PhÃ¡t hiá»‡n cÃ¢u há»i phá»§ Ä‘á»‹nh (náº¿u cÃ³)

**BÆ°á»›c 2: TÃ¬m báº±ng chá»©ng trong tÃ i liá»‡u**
- Duyá»‡t qua tÃ i liá»‡u tÃ¬m thÃ´ng tin liÃªn quan
- Ghi chÃº nguá»“n (Äoáº¡n sá»‘ máº¥y)

**BÆ°á»›c 3: Äá»‘i chiáº¿u Tá»ªNG lá»±a chá»n**
- A: [CÃ³ trong tÃ i liá»‡u? â†’ ÄÃºng/Sai vÃ¬...]
- B: [CÃ³ trong tÃ i liá»‡u? â†’ ÄÃºng/Sai vÃ¬...]
- C: [CÃ³ trong tÃ i liá»‡u? â†’ ÄÃºng/Sai vÃ¬...]
- D: [CÃ³ trong tÃ i liá»‡u? â†’ ÄÃºng/Sai vÃ¬...]

**BÆ°á»›c 4: Káº¿t luáº­n**
- Liá»‡t kÃª Táº¤T Cáº¢ Ä‘Ã¡p Ã¡n Ä‘Ãºng
- Kiá»ƒm tra láº¡i cÃ³ bá» sÃ³t khÃ´ng

### YÃŠU Cáº¦U Äá»ŠNH Dáº NG (Bá»®A BUá»˜C):
Tráº£ lá»i ÄÃšNG format JSON (khÃ´ng thÃªm markdown hay text nÃ o khÃ¡c):

{{
  "reasoning": "Giáº£i thÃ­ch ngáº¯n gá»n cÃ¡ch tÃ¬m Ä‘Ã¡p Ã¡n vÃ  lÃ½ do chá»n",
  "analysis": {{
    "A": "ÄÃºng/Sai - LÃ½ do",
    "B": "ÄÃºng/Sai - LÃ½ do",
    "C": "ÄÃºng/Sai - LÃ½ do",
    "D": "ÄÃºng/Sai - LÃ½ do"
  }},
  "correct_count": <sá»‘ nguyÃªn tá»« 1-4>,
  "correct_answers": ["A", "B", ...]
}}

### LÆ¯U Ã QUAN TRá»ŒNG:
- Náº¿u cÃ¢u há»i dáº¡ng "Äiá»u nÃ o SAI?", chá»n Ä‘Ã¡p Ã¡n KHÃ”NG Ä‘Ãºng vá»›i tÃ i liá»‡u
- Náº¿u khÃ´ng cháº¯c cháº¯n 100%, KHÃ”NG chá»n Ä‘Ã¡p Ã¡n Ä‘Ã³
- correct_count PHáº¢I khá»›p vá»›i sá»‘ pháº§n tá»­ trong correct_answers
- LuÃ´n cÃ³ Ã­t nháº¥t 1 Ä‘Ã¡p Ã¡n Ä‘Ãºng

### TRáº¢ Lá»œI:
"""

    def _parse_llm_response(self, response: str) -> Tuple[int, List[str]]:
        """Parse JSON vá»›i fallback thÃ´ng minh hÆ¡n."""
        try:
            # Loáº¡i bá» markdown
            response = re.sub(r'```json\s*|\s*```', '', response.strip())
            
            # TÃ¬m JSON object
            match = re.search(r'\{[\s\S]*\}', response)
            if match:
                data = json.loads(match.group(0))
                answers = sorted([
                    str(ans).upper() 
                    for ans in data.get("correct_answers", []) 
                    if str(ans).upper() in 'ABCD'
                ])
                
                if not answers:
                    raise ValueError("KhÃ´ng cÃ³ Ä‘Ã¡p Ã¡n trong JSON")
                
                # Validate count
                count = len(answers)
                declared_count = data.get("correct_count", count)
                
                if count != declared_count:
                    print(f"  âš  Cáº£nh bÃ¡o: count khÃ´ng khá»›p ({declared_count} vs {count}), dÃ¹ng {count}")
                
                return count, answers
            
            raise ValueError("KhÃ´ng tÃ¬m tháº¥y JSON")
            
        except Exception as e:
            print(f"  âš  Parse tháº¥t báº¡i: {e}. DÃ¹ng fallback.")
            return self._fallback_parse(response)

    def _fallback_parse(self, response: str) -> Tuple[int, List[str]]:
        """Fallback parsing vá»›i nhiá»u chiáº¿n lÆ°á»£c."""
        # Strategy 1: TÃ¬m "correct_answers": [...]
        pattern1 = r'["\']correct_answers["\']\s*:\s*\[(.*?)\]'
        match = re.search(pattern1, response, re.DOTALL)
        if match:
            answers_str = match.group(1)
            answers = sorted(list(set(re.findall(r'["\']([A-D])["\']', answers_str))))
            if answers:
                return len(answers), answers
        
        # Strategy 2: TÃ¬m pattern "A, B, C"
        pattern2 = r'(?:Ä‘Ã¡p Ã¡n|answers?)[\s:]+([A-D](?:\s*,\s*[A-D])*)'
        match = re.search(pattern2, response, re.IGNORECASE)
        if match:
            answers = sorted(list(set(re.findall(r'[A-D]', match.group(1)))))
            if answers:
                return len(answers), answers
        
        # Strategy 3: Äáº¿m sá»‘ láº§n xuáº¥t hiá»‡n cá»§a má»—i chá»¯ cÃ¡i
        counts = {letter: len(re.findall(rf'\b{letter}\b', response)) 
                  for letter in 'ABCD'}
        
        # Chá»n cÃ¡c chá»¯ cÃ¡i xuáº¥t hiá»‡n nhiá»u nháº¥t (threshold = 2)
        candidates = [k for k, v in counts.items() if v >= 2]
        if candidates:
            return len(candidates), sorted(candidates)
        
        # Strategy 4: Láº¥y táº¥t cáº£ A-D xuáº¥t hiá»‡n
        all_letters = re.findall(r'\b([A-D])\b', response)
        if all_letters:
            unique = sorted(list(set(all_letters)))
            # Náº¿u quÃ¡ nhiá»u (>2), chá»‰ láº¥y 2 Ä‘áº§u
            if len(unique) > 2:
                unique = unique[:2]
            return len(unique), unique
        
        # Final fallback: chá»n A
        print("  âš  KhÃ´ng parse Ä‘Æ°á»£c, máº·c Ä‘á»‹nh chá»n A")
        return 1, ["A"]

    def _expand_query(self, question: str, options: dict) -> List[str]:
        """Táº¡o nhiá»u query variants Ä‘á»ƒ tÄƒng kháº£ nÄƒng tÃ¬m tháº¥y thÃ´ng tin."""
        queries = [question]  # Query gá»‘c
        
        # ThÃªm query vá»›i keywords tá»« options
        valid_options = [v for v in options.values() if v and str(v).strip()]
        if valid_options:
            # Láº¥y 2-3 tá»« khÃ³a quan trá»ng tá»« má»—i option
            keywords = []
            for opt in valid_options[:2]:  # Chá»‰ láº¥y 2 options Ä‘áº§u
                words = re.findall(r'\b\w{4,}\b', str(opt))
                keywords.extend(words[:3])
            
            if keywords:
                queries.append(f"{question} {' '.join(keywords[:5])}")
        
        # TrÃ­ch xuáº¥t keywords tá»« cÃ¢u há»i
        question_keywords = re.findall(r'\b\w{4,}\b', question)
        if len(question_keywords) > 3:
            queries.append(" ".join(question_keywords[:7]))
        
        return queries

    def _rerank_with_keywords(self, question: str, results: list, options: dict) -> list:
        """Re-rank káº¿t quáº£ dá»±a trÃªn keyword matching."""
        # Extract keywords tá»« question vÃ  options
        all_text = question + " " + " ".join(str(v) for v in options.values() if v)
        keywords = set(re.findall(r'\b\w{3,}\b', all_text.lower()))
        
        scored = []
        for point in results:
            content = point.payload.get('content', '').lower()
            
            # TÃ­nh keyword overlap
            content_words = set(re.findall(r'\b\w{3,}\b', content))
            overlap = len(keywords & content_words)
            keyword_score = overlap / max(len(keywords), 1)
            
            # TÃ­nh density (keyword xuáº¥t hiá»‡n gáº§n nhau hÆ¡n = tá»‘t hÆ¡n)
            density_score = self._calculate_keyword_density(content, keywords)
            
            # Káº¿t há»£p Ä‘iá»ƒm
            combined = point.score * 0.5 + keyword_score * 0.3 + density_score * 0.2
            scored.append((combined, point))
        
        scored.sort(key=lambda x: x[0], reverse=True)
        return [p for _, p in scored]

    def _calculate_keyword_density(self, text: str, keywords: set) -> float:
        """TÃ­nh máº­t Ä‘á»™ keywords (keywords xuáº¥t hiá»‡n gáº§n nhau)."""
        positions = []
        words = text.split()
        
        for i, word in enumerate(words):
            if word.lower() in keywords:
                positions.append(i)
        
        if len(positions) < 2:
            return 0.0
        
        # TÃ­nh khoáº£ng cÃ¡ch trung bÃ¬nh giá»¯a cÃ¡c keywords
        distances = [positions[i+1] - positions[i] for i in range(len(positions)-1)]
        avg_distance = sum(distances) / len(distances)
        
        # Score cao hÆ¡n khi keywords gáº§n nhau
        return 1.0 / (1.0 + avg_distance / 10)

    def _extract_context_smart(self, question: str, results: list, 
                               options: dict, max_tokens: int = 2500) -> str:
        """TrÃ­ch xuáº¥t context thÃ´ng minh vá»›i prioritization."""
        if not results:
            return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan."
        
        # Re-rank
        ranked = self._rerank_with_keywords(question, results, options)
        
        context_parts = []
        current_tokens = 0
        seen_content = set()
        
        for idx, point in enumerate(ranked, 1):
            content = point.payload.get('content', '').strip()
            source = point.payload.get('source', 'N/A')
            score = point.score
            
            # Skip duplicates
            content_hash = hash(content)
            if content_hash in seen_content:
                continue
            seen_content.add(content_hash)
            
            # Estimate tokens
            est_tokens = len(content) // 4
            
            if current_tokens + est_tokens > max_tokens:
                break
            
            # Highlight keywords (optional, giÃºp LLM focus)
            highlighted = self._highlight_keywords(content, question, options)
            
            context_parts.append(
                f"[Äoáº¡n {idx} - Nguá»“n: {source} | Score: {score:.3f}]\n{highlighted}"
            )
            current_tokens += est_tokens
        
        return "\n\n" + "="*60 + "\n\n".join(context_parts)

    def _highlight_keywords(self, text: str, question: str, options: dict) -> str:
        """Highlight keywords quan trá»ng báº±ng ** **."""
        # Extract keywords
        all_text = question + " " + " ".join(str(v) for v in options.values() if v)
        keywords = set(re.findall(r'\b\w{4,}\b', all_text.lower()))
        
        # Highlight (chá»‰ highlight 1 láº§n Ä‘á»ƒ khÃ´ng lÃ m rá»‘i)
        highlighted = text
        for kw in keywords:
            pattern = re.compile(rf'\b({re.escape(kw)})\b', re.IGNORECASE)
            # Chá»‰ thay tháº¿ láº§n Ä‘áº§u tiÃªn
            highlighted = pattern.sub(r'**\1**', highlighted, count=1)
        
        return highlighted

    def answer_question(self, question: str, options: dict) -> Tuple[int, List[str]]:
        """Pipeline RAG Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cao."""
        # Clean options
        cleaned_options = {}
        for key, value in options.items():
            if pd.isna(value):
                cleaned_options[key] = ""
            else:
                cleaned_options[key] = str(value).strip()
        
        # BÆ°á»›c 1: Multi-query search
        queries = self._expand_query(question, cleaned_options)
        
        all_results = []
        for query in queries:
            # TÄƒng top_k vÃ  giáº£m threshold Ä‘á»ƒ recall cao hÆ¡n
            results = self.vector_store.search(query, top_k=5, threshold=0.2)
            all_results.extend(results)
        
        # Deduplicate
        seen = set()
        unique_results = []
        for point in all_results:
            content = point.payload.get('content', '')
            if content not in seen:
                seen.add(content)
                unique_results.append(point)
        
        # BÆ°á»›c 2: Extract context thÃ´ng minh
        context = self._extract_context_smart(
            question, unique_results, cleaned_options, max_tokens=2500
        )
        
        # BÆ°á»›c 3: Generate prompt vÃ  gá»i LLM
        prompt = self._create_qa_prompt(question, cleaned_options, context)
        response = self.llm.invoke(prompt)
        
        # BÆ°á»›c 4: Parse káº¿t quáº£
        count, answers = self._parse_llm_response(response)
        
        # Validation cuá»‘i
        if count == 0 or not answers:
            print("  âš  Fallback: chá»n A")
            count, answers = 1, ["A"]
        
        return count, answers

    def process_questions_csv(self, csv_path: Path) -> List[Tuple] | None:
        """Xá»­ lÃ½ CSV vá»›i progress tracking."""
        try:
            df = pd.read_csv(csv_path)
        except FileNotFoundError:
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y {csv_path}")
            return None
        
        results = []
        total = len(df)
        print(f"\nğŸ¤” Báº¯t Ä‘áº§u tráº£ lá»i {total} cÃ¢u há»i...\n")
        
        for idx, row in df.iterrows():
            question = row.iloc[0]
            options = {
                'A': row.iloc[1], 
                'B': row.iloc[2], 
                'C': row.iloc[3], 
                'D': row.iloc[4]
            }
            
            print(f"\n{'='*70}")
            print(f"CÃ¢u {idx + 1}/{total}: {str(question)[:100]}...")
            print(f"{'='*70}")
            
            count, answers = self.answer_question(question, options)
            results.append((count, answers))
            
            print(f"âœ… Káº¿t quáº£: {count} Ä‘Ã¡p Ã¡n â†’ {', '.join(answers)}")
            print(f"Progress: [{idx + 1}/{total}] ({(idx + 1) / total * 100:.1f}%)")
        
        return results